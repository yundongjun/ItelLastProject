import cv2
import requests
import numpy as np
from ultralytics import YOLO
import torch
import os
import socket
import threading
import time

# Dummy socket to allow running without RPi connection
class DummySock:
    def sendall(self, data: bytes):
        try:
            msg = data.decode().strip()
        except Exception:
            msg = str(data)
        print(f"(buzzer OFFLINE) sendall called with: {msg}")

# --- Display Scaling ---
# Map Ï∞Ω ÌôïÎåÄ Î∞∞Ïú® (ÌôòÍ≤ΩÎ≥ÄÏàò MAP_SCALEÎ°ú Ï°∞Ï†ï Í∞ÄÎä•). Ïòà: 2.0Ïù¥Î©¥ 2Î∞∞ ÌôïÎåÄ ÌëúÏãú
try:
    MAP_SCALE = float(os.getenv("MAP_SCALE", "2.0"))
except Exception:
    MAP_SCALE = 2.0

# --- Socket Client Configuration ---
SERVER_HOST = "10.10.16.41"   # TurtleBot (ROS)
SERVER_PORT = 5000
RPI_HOST = "10.10.16.78"      # Raspberry Pi (Buzzer)
RPI_PORT = 5000

FLAME_TIMEOUT = 5.0  # 5Ï¥à ÎèôÏïà RPiÏóêÏÑú Ïã†Ìò∏ Ïïà Ïò§Î©¥ Í∞êÏßÄ Ìï¥Ï†ú
THERMAL_THRESHOLD = 50.0  # üî• Ïó¥ Í∞êÏßÄ ÏûÑÍ≥ÑÍ∞í (¬∞C)

# --- YOLO Model Loading ---
print("Loading custom model...")
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = YOLO('best.pt')
model.to(device)
print(f"‚úÖ Model loaded successfully on {device}.")

# --- MJPEG Stream URL ---
MJPEG_URL = "http://10.10.16.78:8080/?action=stream"

# --- Global States ---
flame_detected_by_rpi = False
last_flame_time = 0
current_temp = 0.0


# ============================================================
# üîπ RPi ‚Üí Ubuntu Î©îÏãúÏßÄ ÏàòÏã† (TEMP / FLAME_DETECTED)
# ============================================================
def recv_from_rpi(sock: socket.socket):
    global flame_detected_by_rpi, last_flame_time, current_temp
    try:
        while True:
            data = sock.recv(1024)
            if not data:
                print("üîå RPi disconnected.")
                break

            msg = data.decode().strip()
            # TEMP: Î©îÏãúÏßÄ Ï≤òÎ¶¨
            if msg.startswith("TEMP:"):
                try:
                    temp_val = float(msg.split(":")[1])
                    current_temp = temp_val
                    print(f"üå° Current RPi Temp: {temp_val:.2f}¬∞C")

                    # Ïò®ÎèÑ Í∏∞Ï§ÄÏúºÎ°ú ÌôîÏóº ÌåêÎã®
                    if temp_val >= THERMAL_THRESHOLD:
                        flame_detected_by_rpi = True
                        last_flame_time = time.time()
                    else:
                        flame_detected_by_rpi = False
                except ValueError:
                    print(f"‚ö†Ô∏è Invalid TEMP format: {msg}")

            elif "FLAME_DETECTED" in msg:
                flame_detected_by_rpi = True
                last_flame_time = time.time()
                print("üî• Received FLAME_DETECTED flag from RPi")

            else:
                print(f"üì® RPi says: {msg}")

    except Exception as e:
        print(f"‚ùå Error recv_from_rpi: {e}")


# ============================================================
# üîπ YOLO + RPi Ïó¥ Í∞êÏßÄ + Î≤ÑÏ†Ä Ï†úÏñ¥
# ============================================================
def display_stream(turtle_sock: socket.socket, buzzer_sock: socket.socket):
    global flame_detected_by_rpi, last_flame_time, current_temp

    homography_path = 'homography_matrix.npy'
    map_path = 'map.pgm'

    if not os.path.exists(homography_path) or not os.path.exists(map_path):
        print("‚ùå Map or homography missing.")
        buzzer_sock = DummySock()

    homography_matrix = np.load(homography_path)
    map_img = cv2.imread(map_path)
    # ÌöåÏÉâ Î∞∞Í≤Ω(Ïó¨Î∞±) ÏûêÎèô ÌÅ¨Î°≠
    crop_x, crop_y = 0, 0
    base_map = map_img
    try:
        gray = cv2.cvtColor(map_img, cv2.COLOR_BGR2GRAY)
        edges = np.concatenate((gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]))
        if edges.size:
            bg_val = int(np.bincount(edges.flatten()).argmax())
        else:
            bg_val = int(gray[0, 0])
        mask = np.abs(gray - bg_val) > 5
        rows = np.where(mask.any(axis=1))[0]
        cols = np.where(mask.any(axis=0))[0]
        if rows.size and cols.size:
            y1, y2 = int(rows[0]), int(rows[-1]) + 1
            x1, x2 = int(cols[0]), int(cols[-1]) + 1
            crop_x, crop_y = x1, y1
            base_map = map_img[y1:y2, x1:x2].copy()
    except Exception:
        base_map = map_img
    print("üó∫Ô∏è Map and homography loaded.")

    buzzer_state = 0
    last_trigger_time = 0
    last_coord_sent_time = 0

    print(f"Connecting to stream: {MJPEG_URL}")
    session = requests.Session()
    stream = session.get(MJPEG_URL, stream=True, timeout=10)
    bytes_buffer = bytes()

    while True:
        bytes_buffer += stream.raw.read(4096)
        start = bytes_buffer.find(b'\xff\xd8')
        end = bytes_buffer.find(b'\xff\xd9')
        if start == -1 or end == -1:
            continue

        jpg = bytes_buffer[start:end+2]
        bytes_buffer = bytes_buffer[end+2:]
        frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)
        if frame is None:
            continue

        annotated_frame = frame.copy()
        if abs(MAP_SCALE - 1.0) > 1e-6:
            mh, mw = base_map.shape[:2]
            map_display = cv2.resize(
                base_map, (int(mw * MAP_SCALE), int(mh * MAP_SCALE)), interpolation=cv2.INTER_NEAREST
            )
        else:
            map_display = base_map.copy()

        person_coords = None
        fire_coords = None

        results = model(frame, verbose=False, conf=0.3)
        for r in results:
            for box in r.boxes:
                class_name = model.names[int(box.cls[0])]
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cx, cy = (x1+x2)//2, (y1+y2)//2
                pts = np.array([[[cx, cy]]], dtype=np.float32)
                transformed = cv2.perspectiveTransform(pts, homography_matrix)
                mx, my = int(transformed[0][0][0]), int(transformed[0][0][1])

                color = (0, 255, 0) if class_name == 'person' else (0, 0, 255)
                label = f"{class_name}: {float(box.conf[0]):.2f}"
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(annotated_frame, label, (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                rx = mx - crop_x
                ry = my - crop_y
                if 0 <= rx < base_map.shape[1] and 0 <= ry < base_map.shape[0]:
                    dx = int(rx * MAP_SCALE)
                    dy = int(ry * MAP_SCALE)
                    cv2.circle(map_display, (dx, dy), 10, color, -1)
                    cv2.putText(map_display, class_name, (dx+10, dy),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                if class_name == 'person':
                    person_coords = (mx, my)
                elif class_name == 'fire':
                    fire_coords = (mx, my)

        # üî• Check RPi flame timeout
        if flame_detected_by_rpi and time.time() - last_flame_time > FLAME_TIMEOUT:
            flame_detected_by_rpi = False

        # ‚úÖ AND Ï°∞Í±¥: (ÏÇ¨Îûå + Î∂à + RPi Ïò®ÎèÑ Í∞êÏßÄ)
        if person_coords and fire_coords and flame_detected_by_rpi:
            if buzzer_state == 0:
                buzzer_sock.sendall(b"1\n")
                print(f"üì§ Sent buzzer ON ‚Äî Flame+Person+Temp({current_temp:.1f}¬∞C)")
                buzzer_state = 1
            last_trigger_time = time.time()

            # Ï¢åÌëú Ï†ÑÏÜ° (10Î∂Ñ Í∞ÑÍ≤©)
            if turtle_sock and (time.time() - last_coord_sent_time > 600):
                msg = f"{person_coords[0]},{person_coords[1]},{fire_coords[0]},{fire_coords[1]}\n"
                turtle_sock.sendall(msg.encode())
                print(f"üì§ Sent coords to TurtleBot: {msg.strip()}")
                last_coord_sent_time = time.time()

        else:
            if buzzer_state == 1 and time.time() - last_trigger_time >= 10:
                buzzer_sock.sendall(b"0\n")
                print("üì§ Sent buzzer OFF (conditions cleared)")
                buzzer_state = 0

        cv2.imshow("YOLO Detection", annotated_frame)
        cv2.imshow("Map", map_display)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()


# ============================================================
# üîπ Î©îÏù∏ (ÏÜåÏºì Ïó∞Í≤∞ Ï¥àÍ∏∞Ìôî)
# ============================================================
def main():
    global flame_detected_by_rpi

    # --- Connect to RPi ---
    try:
        buzzer_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        buzzer_sock.connect((RPI_HOST, RPI_PORT))
        print(f"‚úÖ Connected to RPi ({RPI_HOST}:{RPI_PORT})")
    except Exception as e:
        print(f"‚ùå Failed to connect to RPi: {e}")
        return

    if isinstance(buzzer_sock, socket.socket):
        threading.Thread(target=recv_from_rpi, args=(buzzer_sock,), daemon=True).start()

    # --- Connect to TurtleBot ---
    turtle_sock = None
    try:
        turtle_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        turtle_sock.connect((SERVER_HOST, SERVER_PORT))
        print(f"‚úÖ Connected to TurtleBot ({SERVER_HOST}:{SERVER_PORT})")
        threading.Thread(target=recv_loop, args=(turtle_sock,), daemon=True).start()
    except Exception as e:
        print(f"‚ö†Ô∏è Could not connect to TurtleBot: {e}")
        turtle_sock = None

    display_stream(turtle_sock, buzzer_sock)


def recv_loop(sock: socket.socket):
    """TurtleBot ‚Üí Î©îÏãúÏßÄ ÏàòÏã†"""
    try:
        while True:
            data = sock.recv(1024)
            if not data:
                print("üîå TurtleBot connection lost.")
                break
            print("üì• From TurtleBot:", data.decode().strip())
    except Exception as e:
        print(f"‚ùå Error recv_loop: {e}")


if __name__ == "__main__":
    main()
