import cv2
import requests
import numpy as np
from ultralytics import YOLO
import torch
import os
import socket
import threading
import time

# Dummy socket to allow running without RPi connection
class DummySock:
    def sendall(self, data: bytes):
        try:
            msg = data.decode().strip()
        except Exception:
            msg = str(data)
        print(f"(buzzer OFFLINE) sendall called with: {msg}")

# --- Display Scaling ---
# Map ì°½ í™•ëŒ€ ë°°ìœ¨ (í™˜ê²½ë³€ìˆ˜ MAP_SCALEë¡œ ì¡°ì • ê°€ëŠ¥). ì˜ˆ: 2.0ì´ë©´ 2ë°° í™•ëŒ€ í‘œì‹œ
try:
    MAP_SCALE = float(os.getenv("MAP_SCALE", "2.0"))
except Exception:
    MAP_SCALE = 2.0

# ë””ì§€í„¸ ì¤Œ ë°°ìœ¨ (í™˜ê²½ë³€ìˆ˜ DETECT_ZOOM ë¡œ ì¡°ì •. 1.0=ì¤Œ ì—†ìŒ)
try:
    DETECT_ZOOM = float(os.getenv("DETECT_ZOOM", "1.0"))
except Exception:
    DETECT_ZOOM = 1.0

# ì¤‘ì•™ í¬ë¡­ ê¸°ë°˜ ë””ì§€í„¸ ì¤Œ (ëª¨ë¸ ì¶”ë¡  ì „ìš©)
def digital_zoom(frame, zoom=1.5):
    if zoom <= 1.0:
        h, w = frame.shape[:2]
        return frame, (0, 0), w, h
    h, w = frame.shape[:2]
    nh, nw = int(h / zoom), int(w / zoom)
    nh = max(1, nh)
    nw = max(1, nw)
    y1 = max((h - nh) // 2, 0)
    x1 = max((w - nw) // 2, 0)
    crop = frame[y1:y1+nh, x1:x1+nw]
    resized = cv2.resize(crop, (w, h), interpolation=cv2.INTER_LINEAR)
    # ë°˜í™˜: ì¤Œëœ í”„ë ˆì„, í¬ë¡­ ì˜¤í”„ì…‹(x1,y1), ì›ë³¸ í­/ë†’ì´
    return resized, (x1, y1), w, h

# --- Socket Client Configuration ---
SERVER_HOST = "10.10.16.41"   # TurtleBot (ROS)
SERVER_PORT = 5000
RPI_HOST = "10.10.16.78"      # Raspberry Pi (Buzzer)
RPI_PORT = 5000

FLAME_TIMEOUT = 5.0  # 5ì´ˆ ë™ì•ˆ RPiì—ì„œ ì‹ í˜¸ ì•ˆ ì˜¤ë©´ ê°ì§€ í•´ì œ
THERMAL_THRESHOLD = 50.0  # ğŸ”¥ ì—´ ê°ì§€ ì„ê³„ê°’ (Â°C)

# --- YOLO Model Loading ---
print("Loading custom model...")
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = YOLO('best.pt')
model.to(device)
print(f"âœ… Model loaded successfully on {device}.")

# --- MJPEG Stream URL ---
MJPEG_URL = "http://10.10.16.78:8080/?action=stream"

# --- Global States ---
flame_detected_by_rpi = False
last_flame_time = 0
current_temp = 0.0


# ============================================================
# ğŸ”¹ RPi â†’ Ubuntu ë©”ì‹œì§€ ìˆ˜ì‹  (TEMP / FLAME_DETECTED)
# ============================================================
def recv_from_rpi(sock: socket.socket):
    global flame_detected_by_rpi, last_flame_time, current_temp
    try:
        while True:
            data = sock.recv(1024)
            if not data:
                print("ğŸ”Œ RPi disconnected.")
                break

            msg = data.decode().strip()
            # TEMP: ë©”ì‹œì§€ ì²˜ë¦¬
            if msg.startswith("TEMP:"):
                try:
                    temp_val = float(msg.split(":")[1])
                    current_temp = temp_val
                    print(f"ğŸŒ¡ Current RPi Temp: {temp_val:.2f}Â°C")

                    # ì˜¨ë„ ê¸°ì¤€ìœ¼ë¡œ í™”ì—¼ íŒë‹¨
                    if temp_val >= THERMAL_THRESHOLD:
                        flame_detected_by_rpi = True
                        last_flame_time = time.time()
                    else:
                        flame_detected_by_rpi = False
                except ValueError:
                    print(f"âš ï¸ Invalid TEMP format: {msg}")

            elif "FLAME_DETECTED" in msg:
                flame_detected_by_rpi = True
                last_flame_time = time.time()
                print("ğŸ”¥ Received FLAME_DETECTED flag from RPi")

            else:
                print(f"ğŸ“¨ RPi says: {msg}")

    except Exception as e:
        print(f"âŒ Error recv_from_rpi: {e}")


# ============================================================
# ğŸ”¹ YOLO + RPi ì—´ ê°ì§€ + ë²„ì € ì œì–´
# ============================================================
def display_stream(turtle_sock: socket.socket, buzzer_sock: socket.socket):
    global flame_detected_by_rpi, last_flame_time, current_temp

    homography_path = 'homography_matrix.npy'
    map_path = 'map.pgm'

    if not os.path.exists(homography_path) or not os.path.exists(map_path):
        print("âŒ Map or homography missing.")
        buzzer_sock = DummySock()

    homography_matrix = np.load(homography_path)
    map_img = cv2.imread(map_path)
    # íšŒìƒ‰ ë°°ê²½(ì—¬ë°±) ìë™ í¬ë¡­
    crop_x, crop_y = 0, 0
    base_map = map_img
    try:
        gray = cv2.cvtColor(map_img, cv2.COLOR_BGR2GRAY)
        edges = np.concatenate((gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]))
        if edges.size:
            bg_val = int(np.bincount(edges.flatten()).argmax())
        else:
            bg_val = int(gray[0, 0])
        mask = np.abs(gray - bg_val) > 5
        rows = np.where(mask.any(axis=1))[0]
        cols = np.where(mask.any(axis=0))[0]
        if rows.size and cols.size:
            y1, y2 = int(rows[0]), int(rows[-1]) + 1
            x1, x2 = int(cols[0]), int(cols[-1]) + 1
            crop_x, crop_y = x1, y1
            base_map = map_img[y1:y2, x1:x2].copy()
    except Exception:
        base_map = map_img
    print("ğŸ—ºï¸ Map and homography loaded.")

    buzzer_state = 0
    last_trigger_time = 0
    last_coord_sent_time = 0

    print(f"Connecting to stream: {MJPEG_URL}")
    session = requests.Session()
    stream = session.get(MJPEG_URL, stream=True, timeout=10)
    bytes_buffer = bytes()

    while True:
        bytes_buffer += stream.raw.read(4096)
        start = bytes_buffer.find(b'\xff\xd8')
        end = bytes_buffer.find(b'\xff\xd9')
        if start == -1 or end == -1:
            continue

        jpg = bytes_buffer[start:end+2]
        bytes_buffer = bytes_buffer[end+2:]
        frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)
        if frame is None:
            continue

        # ë””ì§€í„¸ ì¤Œ ì ìš© (ëª¨ë¸ ì¶”ë¡ ìš©). í‘œì‹œìš© í”„ë ˆì„ë„ ì¤Œëœ í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë¦½ë‹ˆë‹¤.
        if DETECT_ZOOM > 1.0:
            zoomed_frame, (crop_x1, crop_y1), orig_w, orig_h = digital_zoom(frame, DETECT_ZOOM)
        else:
            zoomed_frame = frame
            crop_x1, crop_y1 = 0, 0
            orig_w, orig_h = frame.shape[1], frame.shape[0]

        annotated_frame = zoomed_frame.copy()
        if abs(MAP_SCALE - 1.0) > 1e-6:
            mh, mw = base_map.shape[:2]
            map_display = cv2.resize(
                base_map, (int(mw * MAP_SCALE), int(mh * MAP_SCALE)), interpolation=cv2.INTER_NEAREST
            )
        else:
            map_display = base_map.copy()

        person_coords = None
        fire_coords = None

        results = model(zoomed_frame, verbose=False, conf=0.3)
        for r in results:
            for box in r.boxes:
                class_name = model.names[int(box.cls[0])]
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cx, cy = (x1+x2)//2, (y1+y2)//2
                # ë§µ ì¢Œí‘œ ë³€í™˜ì€ ì›ë³¸ ì¢Œí‘œê³„ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•˜ë¯€ë¡œ ì¤Œ ë³´ì •
                if DETECT_ZOOM > 1.0:
                    cx_orig = crop_x1 + (cx / DETECT_ZOOM)
                    cy_orig = crop_y1 + (cy / DETECT_ZOOM)
                else:
                    cx_orig, cy_orig = float(cx), float(cy)

                pts = np.array([[[cx_orig, cy_orig]]], dtype=np.float32)
                transformed = cv2.perspectiveTransform(pts, homography_matrix)
                mx, my = int(transformed[0][0][0]), int(transformed[0][0][1])

                color = (0, 255, 0) if class_name == 'person' else (0, 0, 255)
                label = f"{class_name}: {float(box.conf[0]):.2f}"
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(annotated_frame, label, (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                rx = mx - crop_x
                ry = my - crop_y
                if 0 <= rx < base_map.shape[1] and 0 <= ry < base_map.shape[0]:
                    dx = int(rx * MAP_SCALE)
                    dy = int(ry * MAP_SCALE)
                    cv2.circle(map_display, (dx, dy), 10, color, -1)
                    cv2.putText(map_display, class_name, (dx+10, dy),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                if class_name == 'person':
                    person_coords = (mx, my)
                elif class_name == 'fire':
                    fire_coords = (mx, my)

        # ğŸ”¥ Check RPi flame timeout
        if flame_detected_by_rpi and time.time() - last_flame_time > FLAME_TIMEOUT:
            flame_detected_by_rpi = False

        # âœ… AND ì¡°ê±´: (ì‚¬ëŒ + ë¶ˆ + RPi ì˜¨ë„ ê°ì§€)
        if person_coords and fire_coords and flame_detected_by_rpi:
            if buzzer_state == 0:
                buzzer_sock.sendall(b"1\n")
                print(f"ğŸ“¤ Sent buzzer ON â€” Flame+Person+Temp({current_temp:.1f}Â°C)")
                buzzer_state = 1
            last_trigger_time = time.time()

            # ì¢Œí‘œ ì „ì†¡ (10ë¶„ ê°„ê²©)
            if turtle_sock and (time.time() - last_coord_sent_time > 600):
                msg = f"{person_coords[0]},{person_coords[1]},{fire_coords[0]},{fire_coords[1]}\n"
                turtle_sock.sendall(msg.encode())
                print(f"ğŸ“¤ Sent coords to TurtleBot: {msg.strip()}")
                last_coord_sent_time = time.time()

        else:
            if buzzer_state == 1 and time.time() - last_trigger_time >= 10:
                buzzer_sock.sendall(b"0\n")
                print("ğŸ“¤ Sent buzzer OFF (conditions cleared)")
                buzzer_state = 0

        cv2.imshow("YOLO Detection", annotated_frame)
        cv2.imshow("Map", map_display)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()


# ============================================================
# ğŸ”¹ ë©”ì¸ (ì†Œì¼“ ì—°ê²° ì´ˆê¸°í™”)
# ============================================================
def main():
    global flame_detected_by_rpi

    # --- Connect to RPi ---
    try:
        buzzer_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        buzzer_sock.connect((RPI_HOST, RPI_PORT))
        print(f"âœ… Connected to RPi ({RPI_HOST}:{RPI_PORT})")
    except Exception as e:
        print(f"âŒ Failed to connect to RPi: {e}")
        return

    if isinstance(buzzer_sock, socket.socket):
        threading.Thread(target=recv_from_rpi, args=(buzzer_sock,), daemon=True).start()

    # --- Connect to TurtleBot ---
    turtle_sock = None
    try:
        turtle_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        turtle_sock.connect((SERVER_HOST, SERVER_PORT))
        print(f"âœ… Connected to TurtleBot ({SERVER_HOST}:{SERVER_PORT})")
        threading.Thread(target=recv_loop, args=(turtle_sock,), daemon=True).start()
    except Exception as e:
        print(f"âš ï¸ Could not connect to TurtleBot: {e}")
        turtle_sock = None

    display_stream(turtle_sock, buzzer_sock)


def recv_loop(sock: socket.socket):
    """TurtleBot â†’ ë©”ì‹œì§€ ìˆ˜ì‹ """
    try:
        while True:
            data = sock.recv(1024)
            if not data:
                print("ğŸ”Œ TurtleBot connection lost.")
                break
            print("ğŸ“¥ From TurtleBot:", data.decode().strip())
    except Exception as e:
        print(f"âŒ Error recv_loop: {e}")


if __name__ == "__main__":
    main()
